{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26faf954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import rlcard\n",
    "from rlcard import models\n",
    "from rlcard.agents.human_agents.uno_human_agent import HumanAgent, _print_action\n",
    "from rlcard.games.uno.card import UnoCard\n",
    "import tensorflow as tf\n",
    "from rlcard.agents import DQNAgent\n",
    "from rlcard.utils import (\n",
    "    get_device,\n",
    "    set_seed,\n",
    "    tournament,\n",
    "    reorganize,\n",
    "    Logger,\n",
    "    plot_curve,\n",
    "    print_card\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e891dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include in step function of agent to run with output\n",
    "def print_state(state, action_record):\n",
    "    \n",
    "\n",
    "    ''' Print out the state of a given player\n",
    "\n",
    "    Args:\n",
    "        player (int): Player id\n",
    "    '''\n",
    "    _action_list = []\n",
    "    for i in range(1, len(action_record)+1):\n",
    "        if action_record[-i][0] == state['current_player']:\n",
    "            break\n",
    "        _action_list.insert(0, action_record[-i])\n",
    "    for pair in _action_list:\n",
    "        print('>> Player', pair[0]+1, 'chooses ', end='')\n",
    "        _print_action(pair[1])\n",
    "        print('')\n",
    "\n",
    "    curr_player = state['current_player'] + 1\n",
    "    print(f'\\n=============== Player {curr_player} ===============')\n",
    "    UnoCard.print_cards(state['hand'])\n",
    "    print('')\n",
    "    print('=============== Table Card ===============')\n",
    "    UnoCard.print_cards(state['target'], wild_color=True)\n",
    "    print('')\n",
    "    print('========== Players Card Number ===========')\n",
    "    for i in range(state['num_players']):\n",
    "        if i != state['current_player']:\n",
    "            print('Player {} has {} cards.'.format(i+1, state['num_cards'][i]))\n",
    "    print('======== Actions You Can Choose =========')\n",
    "    for i, action in enumerate(state['legal_actions']):\n",
    "        print(str(i)+': ', end='')\n",
    "        UnoCard.print_cards(action, wild_color=True)\n",
    "        if i < len(state['legal_actions']) - 1:\n",
    "            print(', ', end='')\n",
    "    print('\\n')\n",
    "\n",
    "def print_action(action):\n",
    "    ''' Print out an action in a nice form\n",
    "\n",
    "    Args:\n",
    "        action (str): A string a action\n",
    "    '''\n",
    "    UnoCard.print_cards(action, wild_color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opponent = \"Random\"):\n",
    "    device = get_device()\n",
    "    set_seed(42)\n",
    "    env = rlcard.make(\n",
    "            'uno',\n",
    "            config={\n",
    "                'seed': 42,\n",
    "            }\n",
    "        )\n",
    "    agent = DQNAgent(\n",
    "            num_actions=env.num_actions,\n",
    "            state_shape=env.state_shape[0],\n",
    "            mlp_layers=[64,64],\n",
    "            device=device,\n",
    "        )\n",
    "    agents = [agent]\n",
    "    if opponent == \"Random\":\n",
    "        agents.append(RandomAgent(env.num_actions))\n",
    "    else:\n",
    "        agents.append(opponent)\n",
    "    env.set_agents(agents)\n",
    "    with Logger('uno/dqn_results') as logger:\n",
    "        for episode,i in enumerate(range(500)):  # number of episodes\n",
    "            #print(f\"Episode: {i}\")\n",
    "            trajectories, payoffs = env.run(is_training=True)\n",
    "\n",
    "            trajectories = reorganize(trajectories, payoffs)\n",
    "\n",
    "            # Feed transitions into agent memory, and train the agent\n",
    "            # Assume that agent always plays the first position\n",
    "            for ts in trajectories[0]:\n",
    "                agent.feed(ts)\n",
    "\n",
    "            # Evaluate the performance every 10.\n",
    "            if episode % 10 == 0:\n",
    "                logger.log_performance(\n",
    "                    episode,\n",
    "                    tournament(\n",
    "                        env,\n",
    "                        200, #Number of games to run during eval\n",
    "                    )[0]\n",
    "                )\n",
    "\n",
    "        # Get the paths\n",
    "        csv_path, fig_path = logger.csv_path, logger.fig_path\n",
    "\n",
    "    # Plot the learning curve\n",
    "    plot_curve(csv_path, fig_path, 'dqn')\n",
    "\n",
    "    # Save model\n",
    "    if opponent == \"Random\":\n",
    "        save_path = os.path.join('uno/dqn_results', f'vs_Random_model.pth')\n",
    "    else:\n",
    "        save_path = os.path.join('uno/dqn_results', 'vs_pretrained_model.pth')\n",
    "    torch.save(agent, save_path)\n",
    "    print('Model saved in', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game(agents, runs=1, supress_state_print=False, train_dqn=False):\n",
    "    env = rlcard.make(\"uno\")\n",
    "    #Creating agents from list\n",
    "    agent_list = []\n",
    "    for agent in agents:\n",
    "        if agent == \"human\":\n",
    "            agent_list.append(HumanAgent(env.num_actions))\n",
    "        elif agent == \"random\":\n",
    "            agent_list.append(RandomAgent(env.num_actions))\n",
    "        elif agent == \"custom_agent\":\n",
    "            agent_list.append(UnoAgent(env.num_actions))\n",
    "        elif agent == \"custom_agent_color\":\n",
    "            agent_list.append(UnoAgentColorMatching(env.num_actions))\n",
    "        elif agent == \"custom_agent_number\":\n",
    "            agent_list.append(UnoAgentNumberMatching(env.num_actions))\n",
    "        elif agent == \"custom_agent_special\":\n",
    "            agent_list.append(UnoAgentSpecialCard(env.num_actions))\n",
    "        elif agent == \"dqn\" and train_dqn:\n",
    "            train()\n",
    "            device = get_device()\n",
    "            dqn_agent = torch.load('uno/dqn_results/vs_Random_model.pth', map_location=device)\n",
    "            dqn_agent.set_device(device)\n",
    "            agent_list.append(dqn_agent)\n",
    "    env.set_agents(agent_list)\n",
    "    \n",
    "    #start loop here\n",
    "    win_record = []\n",
    "    for x in range(runs):\n",
    "        trajectories = [[] for _ in range(env.num_players)]\n",
    "        state, player_id = env.reset()\n",
    "\n",
    "        # Loop to play the game\n",
    "        trajectories[player_id].append(state)\n",
    "        while not env.is_over():\n",
    "            if not supress_state_print:\n",
    "                print_state(state['raw_obs'],state['action_record'])\n",
    "                time.sleep(1)\n",
    "            action, _ = env.agents[player_id].eval_step(state)\n",
    "            # Environment steps\n",
    "            next_state, next_player_id = env.step(action, env.agents[player_id].use_raw)\n",
    "            # Set the state and player\n",
    "            state = next_state\n",
    "            player_id = next_player_id\n",
    "\n",
    "        # Payoffs\n",
    "        payoffs = env.get_payoffs()\n",
    "        if not supress_state_print:\n",
    "            print('===============     Result     ===============')\n",
    "            if payoffs[0] > 0:\n",
    "                print('Player 1 Wins')\n",
    "                win_record.append(1)\n",
    "            else:\n",
    "                print('Player 2 Wins')\n",
    "                win_record.append(2)\n",
    "            print('')\n",
    "        else:\n",
    "            if payoffs[0] > 0:\n",
    "                win_record.append(1)\n",
    "            else:\n",
    "                win_record.append(2)\n",
    "        \n",
    "    print(f'Game history: {win_record}')\n",
    "    print(f'Player 1 wins: {win_record.count(1)}')\n",
    "    print(f'Player 2 wins: {win_record.count(2)}')\n",
    "    print(f'Win % (p1:p2): {int(win_record.count(1)/len(win_record)*100)}:{int(win_record.count(2)/len(win_record)*100)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(object):\n",
    "    ''' A random agent. Random agents is for running toy examples on the card games\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_actions):\n",
    "        ''' Initilize the random agent\n",
    "\n",
    "        Args:\n",
    "            num_actions (int): The size of the ouput action space\n",
    "        '''\n",
    "        self.use_raw = False\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    @staticmethod\n",
    "    def step(state):\n",
    "        ''' Predict the action given the curent state in gerenerating training data.\n",
    "\n",
    "        Args:\n",
    "            state (dict): An dictionary that represents the current state\n",
    "\n",
    "        Returns:\n",
    "            action (int): The action predicted (randomly chosen) by the random agent\n",
    "        '''\n",
    "        return np.random.choice(list(state['legal_actions'].keys()))\n",
    "\n",
    "    def eval_step(self, state):\n",
    "        ''' Predict the action given the current state for evaluation.\n",
    "            Since the random agents are not trained. This function is equivalent to step function\n",
    "\n",
    "        Args:\n",
    "            state (dict): An dictionary that represents the current state\n",
    "\n",
    "        Returns:\n",
    "            action (int): The action predicted (randomly chosen) by the random agent\n",
    "            probs (list): The list of action probabilities\n",
    "        '''\n",
    "        probs = [0 for _ in range(self.num_actions)]\n",
    "        for i in state['legal_actions']:\n",
    "            probs[i] = 1/len(state['legal_actions'])\n",
    "\n",
    "        info = {}\n",
    "        info['probs'] = {state['raw_legal_actions'][i]: probs[list(state['legal_actions'].keys())[i]] for i in range(len(state['legal_actions']))}\n",
    "\n",
    "        return self.step(state), info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
